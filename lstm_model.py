# -*- coding: utf-8 -*-
"""LSTM model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sAHAnYGr-SkXLY2wpCLpkIQSlkRJKKBt
"""

from google.colab import files
uploaded = files.upload()

!pip install pandas numpy tensorflow scikit-learn matplotlib

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import MinMaxScaler
from google.colab import files
import matplotlib.pyplot as plt

# Upload dataset
uploaded = files.upload()

# Load dataset
file_name = list(uploaded.keys())[0]  # Get uploaded file name
df = pd.read_csv(file_name)

# Convert timestamp to datetime and sort
df["timestamp"] = pd.to_datetime(df["timestamp"])
df = df.sort_values("timestamp")

# Define failure conditions
failure_thresholds = {
    "cpu usage (%)": 90,
    "memory usage (%)": 90,
    "pod restarts": 3
}

# Create failure label (1 = failure, 0 = normal)
df["failure"] = (
    (df["cpu usage (%)"] > failure_thresholds["cpu usage (%)"]) |
    (df["memory usage (%)"] > failure_thresholds["memory usage (%)"]) |
    (df["pod restarts"] > failure_thresholds["pod restarts"])
).astype(int)

# Select features
feature_columns = [
    "cpu usage (%)", "memory usage (%)", "pod restarts",
    "network receive bytes", "network transmit bytes",
    "fs reads total (mb)", "fs writes total (mb)"
]
target_column = "failure"

# Normalize features
scaler = MinMaxScaler()
df[feature_columns] = scaler.fit_transform(df[feature_columns])

# Convert to numpy arrays
X = df[feature_columns].values
y = df[target_column].values

# Define sequence length
sequence_length = 10

def create_sequences(X, y, seq_length):
    X_seq, y_seq = [], []
    for i in range(len(X) - seq_length):
        X_seq.append(X[i:i+seq_length])
        y_seq.append(y[i+seq_length])
    return np.array(X_seq), np.array(y_seq)

X_seq, y_seq = create_sequences(X, y, sequence_length)

# Train-test split
split_index = int(len(X_seq) * 0.8)
X_train, X_test = X_seq[:split_index], X_seq[split_index:]
y_train, y_test = y_seq[:split_index], y_seq[split_index:]

# Print shapes
print(f"Training data shape: {X_train.shape}, {y_train.shape}")
print(f"Testing data shape: {X_test.shape}, {y_test.shape}")

# Build LSTM model
def build_lstm_model(input_shape):
    model = keras.Sequential([
        layers.LSTM(50, activation="relu", return_sequences=True, input_shape=input_shape),
        layers.LSTM(50, activation="relu"),
        layers.Dense(1, activation="sigmoid")  # Sigmoid for binary classification
    ])
    model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
    return model

# Initialize model
input_shape = (X_train.shape[1], X_train.shape[2])
lstm_model = build_lstm_model(input_shape)

# Train model
history = lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

# Save model
lstm_model.save("k8s_failure_model.h5")
print("âœ… Model saved as k8s_failure_model.h5")

# Evaluate model
loss, accuracy = lstm_model.evaluate(X_test, y_test)
print(f"ðŸ” Test Accuracy: {accuracy:.4f}")

# Predict on test data
y_pred_prob = lstm_model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary (0 or 1)

# Print a sample of predictions
print("ðŸ”¹ Predicted Failures (1 = Failure, 0 = Normal):")
print(y_pred[:20].flatten())  # Print first 20 predictions

